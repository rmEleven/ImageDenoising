# 0. 总结

这篇论文提出了一个称为SC-VAE的变分自编码器模型。该模型的主要创新点是在变分自编码器的潜在空间中使用稀疏编码来表示图像。具体来说,该模型的主要贡献有:

1. 在变分自编码器框架中集成了可学习的迭代稀疏阈值算法(Learnable ISTA),以获得图像的稀疏潜在表示。这种表示包含少数活动原子的线性组合。

2. 相比现有的变分自编码器方法,提出的SC-VAE模型在图像重建质量上取得显著改进。在FFHQ和ImageNet两个数据集上的实验表明,SC-VAE相较基线方法可以获得更高的PSNR和SSIM。

3. 学习到的稀疏码向量允许进行下游任务,比如通过对图像patch进行分组实现无监督的图像分割。

4. SC-VAE模型克服了现有VAE模型中的后验崩塌和码本崩塌问题。它允许梯度通过字典进行反向传播,并可以端到端训练。

5. 通过分析不同的稀疏性参数 $λ$,展示了稀疏性惩罚与图像重建质量之间的权衡关系。

6. 通过对图像patch的稀疏码向量进行聚类,表明相似patch对应的稀疏码也相似,验证了学习到的稀疏表示的有效性。

总体来说,该论文通过在VAE框架中使用可学习的稀疏编码算法,提出了一种新的变分自编码器模型SC-VAE,相较主流的VAE方法,该模型在图像重建和下游任务上都展现出了优势。

## 0.1 SC-VAE模型

1. 网络结构:

(1) 编码器E:包含卷积层,批规一化层,激活函数层等模块,通过下采样减小特征图大小,输出为隐空间特征表示 $E(x)$ ,shape为 $[h,w,n]$。

(2) 字典D:全连接层组成,学习 $n \times K$ 大小的字典, $K$ 为原子数,每个原子是 $n$ 维向量。

(3) LISTA网络:包含可学习的滤波矩阵、抑制矩阵和阈值化函数,通过 $L$ 层迭代学习稀疏码 $z$ ,实现算法展开。

(4) 解码器G:包含反卷积层,批规一化层等模块,通过上采样还原为原图像大小,实现解码。

2. 工作流程:

(1) 输入图像 $x$ 先通过编码器E,获得隐空间表示 $E(x)$ ,按patches切分为 $[E_{ij}(x)]$ , $ij$ 为patch索引。

(2) 每个patch特征 $E_{ij}(x)$ 进入LISTA网络,迭代学习对应的稀疏码 $z_{ij}$。

(3) 字典D将每个 $z_{ij}$ 与所有原子做内积,实现线性重构,得到重构的隐空间表示 $[D_{z_{ij}}]$。

(4) 解码器G将重构的隐向量还原为图像,即 $G(Dz)$。

(5) 网络通过图像重建损失、特征重建损失以及稀疏正则,实现端到端训练。

(6) 最终学习到可用于图像压缩、重建以及下游任务的稀疏表达。

3. 创新点:

相比传统VAE使用固定先验或Vector Quantization,SC-VAE集成了可微分的稀疏编码,兼具了全局和局部建模的能力,避免了posterior collapse等问题,增强了重建质量。端到端集成了可学习的迭代优化算法ISTA,实现了迭代算法的可微分。

## 0.2 稀疏与变分

1. 稀疏编码的实现:

(1) 利用可学习的ISTA(LISTA)网络对每个图像patch的编码学习对应的稀疏码向量z。

(2) LISTA网络包含L层可学习的迭代优化过程,每层学习一个稀疏码z。

(3) 通过加入L1正则项||z||_1进行稀疏性诱导,最终得到只有少数分量非零的稀疏码z。

(4) 字典D将稀疏码z线性组合,重构为图像patch的隐向量表示。

2. 变分学习的实现:

(1) 编码器E学习将图像映射到隐向量空间的编码分布q(z|x)。

(2) LISTA网络学习图像patch与对应的稀疏码z之间的条件分布q(z|E(x))。

(3) 解码器G学习从稀疏码z到图像x的解码分布p(x|z)。

(4) 整个网络实现了对隐变量z的变分推断,综合了编码器、字典、解码器对z的约束,学习图像的稀疏变分表达。

(5) 通过重构损失进行变分学习,使编码/解码分布接近真实分布。

综上,论文通过集成LISTA网络实现了稀疏性诱导,并将其嵌入到变分自编码器框架中,实现了端到端的稀疏变分学习。

# 1. Introduction

这个部分主要介绍了文章研究的背景和动机。具体来说:

1. 学习无标注数据的有效视觉表示是将深度学习应用于下游监督任务的关键挑战。变分自编码器(VAE)及其变体被广泛使用来学习数据的低维表示。

2. 根据对先验分布的假设,现有的VAE方法可以分为两大类:连续型VAE和离散型VAE。

3. 连续型VAE通常假设潜在空间有一个固定的先验分布(如高斯分布),用于正则化潜在表示。
   - 真实世界的数据集不能简单地用一个单一的分布来建模
   - 如果解码器具有足够的表达能力,这类方法存在后验崩塌的问题,在复杂图像上重建效果较差。
   - 虽然潜在表示可以很好地捕获输入的全局结构,但很难捕获复杂的局部结构。

4. 离散型VAE利用向量量化(VQ)和码本来学习先验分布,可以避免后验崩塌。
   - 需要一个大的码本来保存编码观测的信息,这导致了模型参数的增加和码本崩溃问题
   - 倾向于在重建的图像中生成重复的人工模式,因为VQ算子使用相同的量化索引来合并相似的图像。
   - VQ操作符不允许梯度回传,优化更慢,需要Gumbel-Softmax方法或直通估计器来近似梯度。

5. 文章提出将稀疏编码与VAE框架相结合,以克服上述两类VAE的缺陷。稀疏编码可以看作连续和离散表示的折衷,每次只使用少数原子进行重建。

6. 传统的稀疏编码算法如ISTA不允许端到端训练,文章采用可学习ISTA算法进行算法展开,以实现端到端的模型训练。

7. 文章假设将VAE与稀疏编码相结合可以获得更好的图像重建效果。

总体来说,这部分阐明了研究背景、现有方法的局限性以及文章的研究动机和创新点。

## 补充知识点

### 1. Continuous VAE & Posterior Collapse

关于连续型变分自编码器和后验崩塌,我来详细说明一下:

1. 连续型变分自编码器(Continuous VAE)假设潜在空间服从某个简单的固定先验分布,比如高斯分布。它利用变分推断来将这个简单先验分布映射到复杂的真实数据分布。

2. 但是,对于像图像这样高维复杂的数据,用单一分布很难进行有效建模。这导致推导出的近似后验分布与真实后验分布存在明显偏差。

3. 后验崩塌(Posterior Collapse)指的是这种情况:近似后验分布崩塌成了与先验分布极为相似的分布。这使得潜在变量被完全忽略,编码器输出就等价于先验分布的随机样本。

4. 导致后验崩塌的原因在于,如果解码器足够表达能力,它本身就可以很好地逼近数据分布,不需要依赖潜在变量的话,那么整个模型就会选择忽略潜在变量,从而导致后验崩塌。

5. 后验崩塌会导致学习到的潜在表示丧失对数据的信息编码能力,无法提取有意义的语义特征,降低了VAE的表达能力。

6. 连续型VAE由于使用固定简单先验分布,在复杂多模态数据上很容易发生后验崩塌,无法获得好的重建效果。

综上所述,后验崩塌是连续型VAE需要面对的关键问题,文章提出的模型通过使用稀疏编码的方式力图避免这一问题。

### 2. Discrete VAE & Codebook Collapse

好的,我来详细解释一下离散型变分自编码器、向量量化、码本以及码本崩塌:

1. 离散型变分自编码器(Discrete VAE)不再假设固定的先验分布,而是利用向量量化(Vector Quantization, VQ)的方式学习先验分布,形成一个码本(Codebook)。

2. VQ是一种对连续表示进行量化的运算。它将输入映射到离散的码字,码字取自一个固定的码本。码本中的每个码字可以看作是一个离散的语义单元。

3. 离散型VAE使用神经网络来学习一个编码器,将输入编码成离散索引,通过索引在码本中取出对应的码字,再使用解码器重构输入。

4. 优化过程会学习到一个连续空间到离散码本的映射,使得重构误差最小化。

5. 但是,为了保留足够信息,离散型VAE需要使用非常大的码本,这又带来了码本崩塌(Codebook Collapse)的问题。

6. 码本崩塌指的是在训练过程中,大量码字会被归于同一个索引,从而使得码本的表达能力不足。这会降低模型的重建质量。

7. 此外,向量量化也不允许直接进行梯度回传,需要使用一些近似的方法。

综上,离散型VAE使用VQ和码本避免了后验崩塌,但带来了新的问题,如码本崩塌等。文章提出的模型试图结合两者的优点。

# 2. Related Work

## 2.1. Continuous VAEs

这个部分介绍了连续型变分自编码器的相关工作。首先提到了最标准的VAE模型,它们使用高斯分布作为潜在空间的先验。还提到了一些改进连续型VAE的方法,如δ-VAE,它使用相关先验分布来缓解后验崩塌;一些方法利用最优传输理论进行从先验到后验的转换等。但连续型VAE根本的问题仍未解决。

1. 首先提到最标准的VAE模型是Kingma和Welling在2013年提出的,它使用了高斯分布作为潜在空间的先验分布。

2. 然后提到了一些改进连续型VAE的工作:
(1) Chen等人的工作探索了VAE中不可分离表示的来源。
(2) An等人提出了AE-OT模型,使用扩展的半离散最优传输理论。
(3) Kim和Mnih的Disentangling by Factorising通过因式分解潜在变量以实现不可分离。
(4) Razavi等人的δ-VAE使用了相关的先验分布和均场近似后验分布来缓解后验崩塌。
(5) Tolstikhin等人提出Wasserstein Auto-Encoder也使用了最优传输框架。

3. 但是这些连续型VAE方法仍未从根本上解决后验崩塌的问题,因为实际数据的多模态分布很难通过单一的先验分布进行建模。

4. 因此,连续型VAE往往会在表达能力足够强的解码器情况下忽略潜在变量,导致后验崩塌,无法提取有意义的表示。

5. 复杂图像数据上的后验崩塌会导致这类VAE重建效果较差。

## 2.2 Discrete VAEs

这个部分讨论了离散型变分自编码器的相关工作。首先是VQ-VAE,它使用向量量化来获得离散表示,避免后验崩塌。后面还提到许多基于VQ-VAE的改进,如VQGAN、ViT-VQGAN等,它们通过对抗训练或者感知损失来提高生成效果。但离散型VAE存在码本崩塌等问题。

1. 首先提到了VQ-VAE,它是于2017年提出,使用了向量量化的方式来获得离散的潜在表示,避免了后验崩塌的问题。

2. 在VQ-VAE之后,又提出了许多基于向量量化的变种来改进图像生成效果:

(1) VQGAN添加了对抗训练和感知损失。

(2) ViT-VQGAN融合了Vision Transformer和VQGAN的优点。

(3) RQ-VAE使用残差量化保留编码信息且设计紧凑的码本。 

(4) Mo-VQGAN加入了条件normalization层为离散表示加入空间变化信息。

3. 虽然基于VQ的VAE克服了后验崩塌,但仍面临码本崩塌的问题。

4. 另外向量量化本身也不允许直接梯度回传,需要使用Gumbel softmax或straight-through estimator进行近似。

5. 所以离散型VAE虽然在图像生成效果上有改进,但在重建质量和训练过程方面还存在可优化的空间。

## 2.3. Sparse Coding and Algorithm Unrolling

这个部分讨论了稀疏编码与算法展开的相关工作。稀疏编码广泛用于图像表示学习。传统算法如ISTA不支持梯度回传,文章使用了可学习ISTA进行算法展开,以实现端到端训练。

1. 稀疏编码广泛用于图像表示学习,以获得高效的图像表示。

2. 典型的稀疏编码算法包括K-SVD、ISTA、FISTA等,将信号表示为少数原子的线性组合。

3. 但是这些迭代优化算法不能直接用于端到端的神经网络训练。

4. 为了解决这个问题,Gregor等在2010年提出了可学习ISTA(Learnable ISTA),进行了算法展开,可以通过反向传播进行训练。

5. 近年来算法展开成为使迭代算法可微分的重要手段,被广泛应用到信号处理任务中。

6. 例如Meyer等使用深层K-SVD进行去噪;Simon和Elad改进了CSC模型。

7. 因此,算法展开提供了一种将迭代稀疏编码算法集成到端到端模型训练的可行途径。

8. 文章运用了这一思路,使用可学习ISTA将稀疏编码集成到VAE框架中,形成端到端可训练的模型。

# 3. Preliminaries

## 3.1. Sparse Coding

1. 给定输入向量 $X$ ,稀疏码向量 $Z$ ,以及字典矩阵 $D$ ,稀疏编码的目标是用少量的原子来重构 $X$。

2. 它通过最小化以下能量函数来实现:

$E_D(X,Z) = \displaystyle\frac{1}{2}||X - DZ||_2^2 + λ||Z||_1$

3. 该函数由两项组成:

(1) 数据项 $||X - DZ||_2^2$ ,衡量重构误差。

(2) 正则项 $λ||Z||_1$ ,引入稀疏性,其中 $λ$ 控制稀疏度。

4. 通过最小化该目标函数,可以学习到一个用少数字典原子重构输入 $X$ 的稀疏码 $Z$。

5. 该模型提供了一种折衷的图像表示方式,既包含全局结构,也保留局部细节。

6. 因此,稀疏编码可以避免VAE中连续表示过于光滑和离散表示过于重复的问题。

7. 传统算法如ISTA可以求解该稀疏编码问题,但不可微分,不能直接用于神经网络。

8. 文章以此为动机,提出使用可学习ISTA进行端到端训练。

## 3.2. ISTA and Learnable ISTA

1. ISTA是求解稀疏编码最优化问题的经典算法,通过迭代优化求解稀疏码 $Z$。

2. ISTA的迭代公式为:

$Z(t+1) = h_{\theta}(W_eX + SZ(t))$

其中:

$W_e = \displaystyle\frac{1}{L} D^T$ ,为滤波矩阵

$S = I - \displaystyle\frac{1}{L} D^TD$ ,为抑制矩阵

$[h_{\theta}(V)]_i = sign(V_i)(|V_i| - \theta_i)_+$ 为阈值化函数,引入稀疏性

3. LISTA是ISTA的可学习版本,将上述矩阵作为可训练的参数,迭代过程称为时间展开。

4. 通过反向传播,可以端到端训练LISTA算法以实现稀疏编码。

5. 与ISTA类似,LISTA的迭代公式为:

$Z(t+1) = h_{\theta}(W_{e(t)}X + S(t)Z(t)) $

其中 $W_e(t)$ , $S(t)$ 为第 $t$ 层的可训练滤波矩阵与抑制矩阵。

1. 文章运用了LISTA的思想,将其集成到VAE框架中,实现端到端的训练。

2. LISTA提供了一种使传统迭代算法可微分的有效途径,文章将其应用到了稀疏编码上。

## 补充知识点

### 1. 码本与字典

码本(Codebook)和字典(Dictionary)在概念上有些细微的区别:

1. 码本通常出现在向量量化(Vector Quantization)中,是预先定义好的一组离散的量化码字(Codewords)。

2. 在训练过程中,输入信号会被映射到距离最近的码字,用码字的索引来表示该输入。

3. 字典通常出现在稀疏表示学习中,包含可以线性组合以重构输入信号的基(atoms)。

4. 训练过程需要学习字典以及对应于每个输入的稀疏编码向量。

5. 所以可以看出,码本是预设的,而字典需要学习;码本包含离散码字,字典包含可线性组合的基。

6. 但是二者在实现上都起到表示字典的作用,所以有时会混用这两个术语。

7. 在变分自编码器中,连续型通常没有码本或字典,离散型使用预设码本,文章提出的稀疏编码VAE需要学习字典。

8. 学习到的字典相当于一个连续可微分的码本,使得模型可端到端训练。

9. 综上,字典与码本的区别在于前者是可学习的连续表示,后者是预设的离散表示。

# 4. Approach

## 4.1. Model Formulation

1. 输入图像 $x$ 先通过编码器E获得隐表示 $E(x)$,其shape为 $h×w×n$。

2. 每个隐向量 $E_{ij}(x)$送入LISTA网络,使用字典 $D∈R^{n×K}$ 学习稀疏码 $Z_{ij}∈R^K$。

3. 重构的隐向量为 $DZ_{ij}$ ,解析器G将其解码还原为图像。

4. 编码器E通过下采样,shape变化为 $h=\frac{H}{2^d}$ , $w=\frac{W}{2^d}$。

5. $n$ 为每个隐向量的维度, $K$ 为字典原子数。

6. LISTA网络使用L层可学习的ISTA,学习过程等价于算法展开。

7. 通过学习字典 $D$ 和稀疏码 $Z$ ,实现端到端的图像重建。

8. 相比传统VAE,该模型不需要预定义的先验分布,而是学习字典来获得连续可微分的表示。

9. 稀疏码表示使其同时兼具了全局结构和局部细节的建模能力。

10. 通过集成LISTA网络,SC-VAE实现了端到端的训练过程。

## 4.2. Loss Functions

1. 定义了图像级别和隐表示级别的两个损失函数。

2. 图像重建损失 $L_{rec}$ 为 $L_2$ 损失:
$L_{rec} = ||G(DZ) - x||_2^2$

3. 隐表示重建损失 $L_{latent}$ 为:  

$L_{latent} = \underset{ij}{Σ} ||E_{ij}(x) - DZ_{ij}||_2^2 + λ\underset{ij}{Σ}||Z_{ij}||_1$

其中前项为 $L_2$ 损失,后项引入稀疏正则。

1. 直接相加两项损失会使模型忽略 $L_{rec}$,因此引入 $α_{ij}$ 对隐向量进行加权, $Σ_{ij}α_{ij} = 1$。

2. 最终损失为:
$L_{SC} = ||G(DZ) - x||_2^2 + \underset{ij}{Σ} \alpha_{ij} ||E_{ij}(x) - DZ_{ij}||_2^2 + λ\underset{ij}{Σ}||Z_{ij}||_1$

3. $α_{ij}$ 通过注意力机制来学习,以自动平衡两损失项。

4. 注意力网络结构为:
$E_{ij}$ - $DZ_{ij}$ → 等变层 → $Sigmoid$ → $Softmax$ → $α_{ij}$

5. 通过合理定义的图像级和隐变量级损失,以及引入的注意力机制,可以端到端有效地训练SC-VAE模型。

论文中提到的模型在优化过程中过于关注隐变量级别的损失 $L_{latent}$而忽略图像级别的重建损失 $L_{rec}$ 的原因在于:

1. 模型总损失简单地将两项损失相加:
$L = L_{rec} + L_{latent}$

2. 而 $L_{latent}$ 对每个图像patch的隐向量都是独立进行求和的:
$L_{latent} = Σ_{ij} L_{latent_{ij}}$

3. 一个图像通常会被分割成多个patch(例如32x32个)。

4. 所以 $L_{latent}$ 中的累加求和项数目远多于 $L_{rec}$。

5. 在直接相加两种损失时,模型会倾向于更多地减小数值更大的 $L_{latent}$。

6. 从而忽略了图像整体重建质量对应的 $L_{rec}$。

7. 导致模型仅仅学习到很好的稀疏表达,但整体重建效果不佳。

为了平衡两种损失的比重,论文提出了使用注意力机制来学习权重 $α_{ij}$ ,对每个patch的 $L_{latent}$ 进行平衡。这使得模型既学习到高质量的稀疏表达,也取得良好的整体重建效果。

## 补充知识点

### 1. 误差和残差

简单来讲，误差是观察值与真实值之间的差。经典测验理论（CTT）的基本假设是：X=T+E。也就是说，观察值等于真值加上误差。我们的任何一次测量都带有误差（每一次测量的这个误差具体是多少是不清楚的，只有把所有测量结果进行分析后才知道误差有多大），经典测验理论认为误差是随机分布，且误差均值为0。因此，经过多次测验后，将观测值求平均就可以看作为真值。也就是说，多次测量求得的平均数是真值的最佳估计。

残差是观察值与模型估计值之间的差。以回归分析为例，回归方程y=b0+b1x，当知道b0和b1时这就是一个真实的回归模型。比如y=2+3x。取一个数值（1,2），则模型估计值为y=2+3×1=5。残差为2-5=-3。因此，只要有一个确定的取值以及模型，则模型肯定有一个估计值，也就有一个残差了。对残差进行分析是回归分析的一个重要部分。

### 2. equivariant layer

所谓等变性(equivariance),是指当输入经过一个变换时,输出也相应地发生期望的变换。

等变层是一种特殊设计的层结构,可以保证层的输出对输入的等变性。论文中使用了等变层来构建注意力网络F,其原因如下:

1. 注意力网络F的输入是一组向量 ${E_{ij} - DZ_{ij}}$ ,输出是一组权重 ${α_{ij}}$。

2. 要使得当输入向量组发生置换时,输出权重组也相应地置换,保持等变性。

3. 若使用普通全连接层,则无法保证这一等变性属性。

4. 而等变层可以保证这一期望的输入输出等变性。

具体而言,等变层可以通过以下公式实现:

$H_{ij} = W(H_{ij} - max(H,2)) + b$

这里 $H_{ij}$ 是输入, $W$ 和 $b$ 是可学习的参数。通过减去最大值实现等变变换。

综上,论文使用了等变层构建注意力网络F,是为了保证网络结构对输入的等变性,即当输入发生置换时,输出权重也相应地置换,以满足注意力机制的设计需求。

# 5. Experiments

## 5.1. Image Reconstruction

1. 在FFHQ和ImageNet两个数据集上报告了图像重建的定量结果。

2. 对比了多个连续/离散型VAE作为基线。

3. 使用PSNR、SSIM、LPIPS、FID等指标进行评估。

4. 结果显示,在32x32的隐码大小下,SC-VAE明显优于其他方法,都取得了最高的PSNR和SSIM。

5. 即使降低到16x16的隐码大小,SC-VAE在两个数据集上仍大幅领先其他方法。

6. 连续型VAE由于使用固定简单先验分布,重建效果较差。

7. 离散型VAE受限于码本大小,难以建模细节,有重复误差。

8. 而SC-VAE融合了两者优点,既避免了后验崩塌,又能建模细节。

9. 定量结果证明了SC-VAE相比典型VAE方法,在复杂图像重建任务上获得了显著提升。

10. 重建图像的可视化结果也证实了SC-VAE的优势。

## 5.2. Image Patches Clustering

1. 利用SC-VAE学习到的稀疏码向量,可以对图像patch进行聚类。

2. 从FFHQ验证集中随机采样1000张图像,获得256000个图像patch。

3. 对应的稀疏码向量进行K-Means聚类,获得1000个类。

4. 可视化结果显示,具有相似模式的patch被聚类到了一起。

5. 这验证了SC-VAE学习到的稀疏码向量能够对图像局部结构进行有效表示。

6. 不同于连续表示过于平滑,也不同于离散表示过于死板。

7. SC-VAE以稀疏表示的方式,同时包含了全局和局部信息。

8. 因此,相似patch对应的稀疏码也较为接近,从而可以进行有效的聚类。

9. 这证明了稀疏码向量作为图像压缩表示的有效性。

10. 可用于各种下游任务,如检索、分类等。

所以该实验通过聚类分析,验证了SC-VAE学习到的稀疏表达对图像patch的区分能力。

## 5.3. Unsupervised Image Segmentation

1. 利用SC-VAE的稀疏码向量,测试了无监督的图像分割。

2. 使用在FFHQ和ImageNet上预训练的模型。

3. 将图像分割成n×n的patch,获得对应的稀疏码向量。

4. 通过K-Means算法对这些稀疏码进行聚类,生成图像的分割掩码。

5. 实验中使用5类进行分割。

6. 结果显示,人脸和物体可以成功分割出来。

7. 这再次验证了稀疏码向量对图像局部模式的建模能力。

8. SC-VAE以无监督方式学习到了面部、身体等语义信息。

9. 相比Pixel级表示,稀疏码提供了更高级的特征表示。

10. 通过设计更复杂的基于稀疏码的分割方法,可以获得细粒度的分割结果。

11. 该无监督分割框架可以扩展到各种下游任务中。

12. 相比于基于像素的方法,基于稀疏码更高效。

综上,该实验展示了SC-VAE语义稀疏表示在图像理解任务中的潜在应用价值。

## 5.4. Sparsity Parameter Analysis

1. SC-VAE模型包含一个可调节的稀疏性参数λ,控制稀疏性正则化程度。

2. 在ImageNet数据集上,分析了λ从1到5时,模型重建性能的变化。

3. 结果表明,随着λ增大,稀疏码变得越稀疏,但重建质量下降。

4. 当λ=1时,平均仅7.5%的元素非零,但PSNR达到38.09,SSIM达0.9702。

5. 当λ=5时,平均98.6%元素为零,但PSNR降至27.09,SSIM降至0.7373。

6. 重建图像的可视化也反映了这一趋势。

7. 这表明稀疏性正则化强度与重建误差之间存在权衡。

8. λ的设置可以根据具体应用需求来确定稀疏性。

9. 如果追求重建质量,则取较小λ;如果需高度压缩,则取较大λ。

10. SC-VAE通过λ参数提供了控制稀疏性和重建误差的灵活性。

11. 用户可以自行权衡稀疏表达的压缩率和语义信息量。

综上,该分析验证了稀疏性参数λ能够有效控制稀疏表达的压缩率,为不同应用提供了灵活性。

# 6. Conclusion

1. 文章提出了SC-VAE模型,在VAE框架内集成了稀疏编码。

2. 利用可学习ISTA网络获得了图像的稀疏潜在表示。

3. 相比现有VAE方法,SC-VAE获得了以下几点优势:

(1) 可以端到端训练,没有后验崩塌和码本崩塌问题。

(2) 重建图像质量有显著提升。

(3) 稀疏码可用于下游任务,如图像分割。 

(4) 梯度可以通过字典进行反向传播。

4. 在两个数据集上证明了SC-VAE相比主流VAE的优越性。

5. SC-VAE的优势来源于集成了稀疏编码的表达能力。

6. 稀疏表达使其同时兼具了全局和局部建模能力。

7. SC-VAE为基于无标注数据的图像表示学习提供了一个有效框架。

8. 未来工作可以在下游任务上进一步证明SC-VAE的效果。

9. 总之,SC-VAE是VAE表示学习领域的有价值贡献。
