# 1. Introduction

## 1.1 ill-posed problem

ill-posed problem 指的是在图像复原等问题中,从观测图像中恢复原图的过程中,**问题本身存在不稳定性或非唯一性**的情况。

一个问题要是ill-posed problem,通常具有以下一个或多个特点:

1. 不存在解
2. 存在多个解 
3. 没有连续性,即小的噪声也会导致完全不同的解

图像复原问题往往是ill-posed的,因为从有限的观测数据推断无限可能的原图是有歧义的。这会导致复原结果对噪声非常敏感。 

为了解决这一问题,需要引入合适的先验知识来正则化问题,使其更稳定和接近真实解。所以文中提到,传统方法利用手工设计各种先验(regularization)来约束ill-posed problem。

总之,ill-posed problem是图像复原问题固有的属性,理解这一概念有助于厘清问题的本质。

## 1.2 model-based methods

关于model-based methods,简介部分主要做了以下几点说明:

1. 基于模型的方法通常**从贝叶斯角度将图像复原视为MAP估计问题**,包含数据项和正则项。

2. 使用了各种精细设计的先验,如TV正则化、稀疏表示等来约束问题。

3. 这类方法**解释性好**,但**手工设计的先验能力有限,结果不稳定**。

4. 推理时间较长。

5. 典型的algorithms包括HQS、ADMM和PGD。

6. 但是这些算法对图像退化过程的要求较高,**不易处理复杂真实场景**。

### 补充知识点

#### MAP

MAP估计(Maximum A Posteriori estimation)是一种贝叶斯估计方法,目的是**求出给定观测数据条件下,后验概率最大的模型参数**。

在图像复原任务中,MAP估计的目标是求出在给定受损图像y的条件下,后验概率p(x|y)最大的原图x。根据贝叶斯规则,可以把后验概率表达为数据似然度p(y|x)和图像先验p(x)的乘积:

p(x|y) ∝ p(y|x)p(x)

取对数可得:

logp(x|y) = logp(y|x) + logp(x)

这里,logp(y|x)表示数据项,度量原图x和观测图像y的匹配程度;logp(x)表示正则项,引入对原图x的先验约束。

MAP估计的目标就是最大化logp(x|y),即同时优化数据项和正则项,得到后验概率最大的原图。这与文中公式(2)的推导相对应。

所以,MAP提供了一种优化框架,将图像复原问题表示为数据项和正则项的优化。这种思路广泛用于基于模型的图像复原方法。

#### p(x|y) ∝ p(y|x)p(x)

p(x|y) ∝ p(y|x)p(x)的推导过程如下:

根据贝叶斯规则,后验概率p(x|y)可以表示为:

**p(x|y) = p(y|x)p(x) / p(y)**

这里,
p(y|x) - 表示数据似然度,即给定参数x后得到数据y的概率
p(x) - 表示参数x的先验概率
p(y) - 表示数据y的边缘概率

在图像复原问题中,我们主要关心给定观测图像y后原图x的后验分布p(x|y),而观测图像y是已知的,所以p(y)可以看成一个常数。

将上式两边同时除以p(y),可得到:

p(x|y) = p(y|x)p(x) / p(y) ∝ p(y|x)p(x)

即后验概率p(x|y)与数据似然度p(y|x)和参数先验p(x)的乘积成正比。

这里∝表示“成正比于”的关系。

通过上述推导可得到MAP估计中使用的后验概率表达式p(x|y) ∝ p(y|x)p(x),这也是图像复原问题中贝叶斯估计的数学基础。

#### l1 norm 和 l2 norm

l1 norm 和 l2 norm 是两个常见的矩阵或向量的范数表示方法:

- l1 norm 又称作“稀疏范数”或“曼哈顿距离”,它将向量或矩阵的所有元素的绝对值之和作为范数。对向量x,其l1 norm定义为:
$||x||_1 = Σ|_i| |x_i|$

- l2 norm 又称作“欧几里得范数”或“Euclidean范数”,它将向量或矩阵的所有元素的平方和再开方作为范数。对向量x,其l2 norm定义为:  
$||x||_2 = (Σ_i |x_i|^2)^{1/2}$

图像复原任务中,l1 norm正则化可产生稀疏解,因而广泛用于表示图像的稀疏先验,例如表示图像在某转换域(如小波域)下具有稀疏性。

而数据项通常用l2 norm表示,这相当于最小化解与观测之间的欧氏距离。

所以两者在图像复原中发挥着不同的作用,**l1 norm表达了解的稀疏性**,**l2 norm反映了解与观测的符合程度**。结合两者可以构建图像复原的优化模型。

#### sophisticated priors

该论文提到的几种图像复原领域中的经典先验知识包括:

1. Total Variation(TV):假设图像在gradient域中具有稀疏性,可以用TV范数表示,实现边缘保留的平滑。

2. Sparse Representation: 假设图像在某转换域(如小波域)可由少量基具稀疏表示,采用l1范数可得到稀疏表示。

3. Low-Rank:假设图像包含自相似的局部结构,其矩阵可用低秩表示。采用核范数等正则化可减少冗余。

4. Self-Similarity:假设自然图像中存在大量冗余信息,利用非局部类似区块的冗余性进行复原。

这些先验都反映了图像的某些内在特性,如平滑、稀疏、低秩、自相似等。由于手工设计,其表达能力有限,但为图像复原提供了一定正则化约束,一定程度上缓解了ill-posed问题。这类先验结合数据项可建立图像复原优化模型。

## 1.3 deep learning methods

1. 基于深度学习的方法利用大规模数据集学习强大的图像先验知识,在图像复原任务上取得了令人印象深刻的进展。

2. 提出了许多功能模块来提高性能,如残差学习、密集连接、注意力机制等。

3. 但是其黑盒式设计使得**难以分析不同组件的作用,性能提升往往依赖组件的堆叠**。

4. 缺乏模型可解释性。

5. 推理速度快。

6. 代表性方法包括DnCNN、MemNet等。

7. 目前的深度学习方法侧重提升复原性能,但解释性和泛化性有待改进。

## 1.4 hybrid methods

1. 一些混合方法试图结合深度学习和经典优化算法的优点。

2. 深度插播(PNP)利用预训练的CNN先验/去噪器来表示正则项,集成到迭代优化框架中。

3. PNP方法计算耗时高。

4. 深度展开网络(DUN)方法将传统优化算法展开成端到端的深度网络进行联合训练,给出了更好的结果和更快的推理。

5. 但是大多数DUN方法要求知道精确的退化过程,**对复杂真实场景适应性较差**。

6. 一些工作通过人工设计退化过程来处理特定任务。

7. DUN固有的每个阶段图像输入输出也导致**信息损失**。

### 补充知识点

#### end-to-end

这里的 end-to-end 指的是指将整个模型看作一个统一的框架进行优化,不同于传统的分阶段设计。

具体在深度展开网络(DUN)中,end-to-end 指的是:

1. 将传统迭代优化算法(如ADMM, ISTA等)中的不同模块或步骤表示为神经网络。

2. 将这些神经网络模块组合起来,形成对应迭代优化过程的深度网络结构。

3. 对整个联合的深度网络进行端到端训练,而不是分步训练各个组件。

这种端到端的方式可以获得比分步训练更好的性能,因为各个模块被统一优化以最好地协同解决任务。

而之前的深度插播(PNP)方法则是分开训练去噪模块,然后固定使用,缺乏联合优化。

所以end-to-end训练是DUN的一大创新,也是本文DGUNet的设计思路。

## 1.5 deep generalized unfolding network (DGUNet)

1. DGUNet**将proximal gradient descent算法展开为端到端的深度网络,保持了模型的可解释性**。

2. 与深度学习方法类似,DGUNet可以端到端训练,并具有无障碍的特征传递。

3. DGUNet**在PGD算法的梯度下降步骤中,集成了梯度估计策略,可以处理未知的图像退化**。

4. **设计了跨层信息通道,以一种多尺度、自适应的方式传递特征,缓解了DUN中的信息损失问题**。 

5. 通过集成灵活的梯度下降和信息融合的近似映射,将PGD算法展开为一个可训练的深度网络。

6. 实验表明,DGUNet可以解决通用的图像复原任务,达到或超过当前最先进的性能。

7. DGUNet既保留了模型可解释性,又可以像端到端深度网络一样进行训练,适用于复杂真实场景。

### 补充知识点

#### proximal gradient descent (PGD)

proximal gradient descent (PGD)算法是一种用于求解复合函数优化问题的算法。在图像复原任务中,它常用于求解包含数据项和正则项的问题:

$min f(x) + g(x)$

其中f(x)表示数据项,g(x)表示正则项。

PGD算法基于proximal操作符,将复合函数优化问题分解为两个子问题:

1. 梯度下降: $x_{k} = x_{k-1} - τ∇f(x_{k-1})$

这里$τ$是步长,$∇f(x)$表示f(x)的梯度。这一步相当于更新x以减小数据项f(x)。

2. proximal映射: $x_{k+1} = prox_{τg}(x_k)$

这里prox是 proximal操作符,将x映射到使g(x)足够小的一个点。这一步相当于减小正则项g(x)。

PGD算法将这两个子问题交替迭代,直到收敛为止。

proximal映射实际上相当于一个去噪或 enforcing regularization 的过程。

所以PGD提供了一种迭代优化算法框架,分别更新数据项和正则项,**可解释性强**。本文将其展开为端到端网络。

#### gradient estimation strategy

在论文中,gradient estimation strategy 指的是在图像退化过程未知的情况下,利用数据驱动的方式来估计梯度,从而实现灵活的梯度下降。

具体来说,在 proximal gradient descent (PGD)算法的梯度下降步骤中,需要计算梯度 ∇f(x),其中f(x)是数据项。这个梯度取决于图像退化模型A。

如果A未知,则不能直接计算∇f(x)。为了解决这个问题,论文提出了梯度估计策略:

1. 使用两个独立的卷积块来估计A和A^T。

2. 然后根据估计的A和A^T计算梯度。

也就是说,不再依赖与精确的退化模型,而是学习来自数据的退化相关信息,对梯度进行估计。

这种灵活的梯度估计方式使得PGD算法可以适用于复杂的真实退化情况,不需要人为定义退化模型,增强了算法的泛化能力。这是本文方法的一个创新点。

#### inter-stage information pathways

论文中提出的inter-stage information pathways 是一种跨层的特征融合机制,目的是为了弥补深度展开网络中存在的信息损失问题。

在大多数的深度展开网络(DUN)中,每个阶段的输入输出都是图像,这会导致从特征图到图像的转换中出现信息损失。

为了解决这个问题,论文设计了跨层的特征通道,即inter-stage information pathways,其思路是:

1. 将前一阶段的encoder和decoder特征图,通过专门的融合模块传递到当前阶段。

2. 利用这些先前特征增强当前阶段的特征表达。

3. 采用多尺度的特征融合,在每个尺度上进行。

4. 特征融合模块使用自适应的空间归一化,保留位置信息。

这样可以使更多阶段的信息聚合,降低信息损失,增强网络表达能力。这是论文提出的另一创新之处。

#### multi-scale features

多尺度特征(multi-scale features)指的是图像的不同尺度上的特征表示,它在许多计算机视觉任务中被广泛使用。

图像的不同尺度具有不同的信息:
- 大尺度CAPTURES整体结构和语义信息
- 小尺度包含精细纹理和局部细节

为了综合不同尺度的信息,图像处理系统会提取和融合多尺度特征。具体来说,多尺度特征包括:

- 不同尺寸的感受野:使用不同尺寸的过滤器提取多尺度特征,比如3x3,5x5卷积核。

- 图像金字塔:将图像缩放到不同分辨率,在每个分辨率上提取特征。 

- Pooling:使用不同程度的下采样来获取多尺度特征图,例如最大池化。

多尺度特征编码了图像表达的不同方面,通过组合可以获得比单一尺度特征更丰富的信息。在图像复原任务中,它通常能提升恢复质量和鲁棒性。

本文使用hourglass结构和多分支提取多尺度特征,并在每个尺度引入跨层融合,更充分地利用信息。这是提升网络表达能力的关键之一。

#### spatial-adaptive normalization

空间自适应归一化(spatial-adaptive normalization)是一种对特征图进行可学习归一化的方法。其关键特点是:

1. 针对特征图的每个空间位置(x,y),单独计算该位置的均值和方差,进行归一化。

2. 学习每个位置的可训练缩放和偏置参数,进行仿射变换。

具体来说,对特征图F,计算每个位置(x,y)的均值μ(x,y)和方差σ(x,y),然后学习参数α(x,y),β(x,y),进行以下变换: 

F'(x,y) = α(x,y) * (F(x,y) - μ(x,y)) / σ(x,y) + β(x,y)

与批规范化不同,这里的α和β是一个与位置(x,y)相关的可学习函数,而不是单个常量。

这种机制可以保留特征图的空间信息,学习到位置相关的提升表达。在文章中,运用于跨层特征融合,增强网络的空间建模能力。

相比简单堆叠特征,空间自适应归一化可以传递更丰富的位置依赖关系,提升特征表达能力。这是文章提出的创新之一。

# 2. Related Works

## 2.1 Model-based Image Restoration Methods

1. 从贝叶斯角度将图像复原视为MAP估计问题,包含数据项和正则项。

2. 使用了迭代优化算法来求解,如HQS、ADMM、PGD等。

3. 数据项通常采用L2范数表示图像与观测的差异。

4. 正则项利用手工设计的先验知识进行建模,如TV正则化、稀疏表示等。

5. 这类方法可解释性好,但先验表达能力有限,结果不够稳定。

6. 计算耗时较高。

7. 算法通常通过交替优化数据项和正则项来实现。

8. 但是对精确的退化模型要求较高,难以适应复杂真实场景。

## 2.2 Deep Learning Image Restoration Methods

1. 基于深度学习方法利用大规模数据集学习强大的图像先验。

2. 在低层视觉任务上取得了巨大成功,如DnCNN、MemNet等。 

3. 提出了各种功能模块来提高复原性能,如残差学习、注意力机制等。

4. 但是其黑盒式设计使解释性和泛化性较弱。

5. 性能提升常依赖组件的堆叠,而非算法创新。

6. 计算速度很快。

7. 通过端到端训练获取强大的非参数图像先验。

8. 但缺乏对解的结构假设,不同于模型方法的正则化。

9. 整体来看,深度学习方法追求高性能,但解释性和泛化性有限。

## 2.3 Deep Unfolding Networks

1. 深度展开网络的核心思想是将传统迭代优化算法展开成对应的深度网络结构。

2. 深度插播方法利用预训练去噪器表示正则项,但计算复杂,缺乏联合优化。

3. 深度展开网络可以端到端训练,获得更好性能,如D-AMP等。

4. 但是大多数深度展开网络要求已知精确的图像退化模型,限制了适用范围。

5. 一些工作通过人为设计退化过程来解决特定任务。

6. 现有深度展开网络存在信息损失问题,每个阶段的图像输入输出损失了特征表达。 

7. 尽管一些工作使用跳连接传递特征,但其实现较为简单,如简单拼接。

8. 整体来说,当前深度展开网络对退化过程要求较强,且特征表达能力有限。

# 3. Methodology

## 3.1 Traditional Proximal Gradient Descent

1. 介绍了PGD算法通过迭代逼近的方式求解包含数据项和正则项的复合函数优化问题。

2. PGD算法包含两个子问题:梯度下降更新和proximal映射。

3. 梯度下降步骤计算梯度并沿梯度方向更新,以减小数据项。

4. proximal映射步骤进行阈值化操作,以减小正则项。

5. 这两个子问题交替迭代直到收敛。

6. 当退化过程未知时,无法直接计算梯度,这限制了PGD算法的适用范围。

7. proximal映射相当于一个去噪或正则化过程。

8. 文中提出的方法就是在保持PGD算法框架的基础上,对其进行修改和改进,拓宽其适用范围。

### 补充知识点

#### $v_k = x_{k-1} - ρA^T(Ax_{k-1} - y)$

这代表了PGD算法中的梯度下降(Gradient Descent)更新步骤。其中:

v_k表示更新后的向量
x_{k-1}是前一次迭代的结果
ρ是步长参数
A是退化矩阵
y是观测图像
这一步相当于计算数据项的梯度,并沿梯度方向更新结果,以减小数据项和观测图像之间的误差。

#### $x_k = prox_{λ,J}(v_k)$

这代表了PGD算法中的proximal映射(Proximal Mapping)步骤。其中:

prox表示proximal运算
λ控制正则项的权重
J表示正则项
该步骤使结果向更加符合正则项J的方向更新,玩减小正则化项,相当于一种去噪或正则化过程。

## 3.2 Proposed Deep Generalized Unfolding Network

1. 概述了DGUNet的整体网络架构,包含多个重复的阶段,每个阶段对应PGD算法的一次迭代。

2. 每个阶段包含灵活梯度下降模块(FGDM)和信息融合的Proximal映射模块(IPMM)。

3. FGDM模块融入了梯度估计策略,可以处理未知的图像退化情况。

4. IPMM模块采用hourglass结构提取多尺度特征。

5. 设计了跨阶段的特征融合路径,使用空间自适应规范化,以弥补DUN的信息损失。 

6. 最终将PGD算法展开为端到端可训练的深度网络。

7. 提出了参数量不同的两种网络结构DGUNet和DGUNet+。

**论文中提出的灵活梯度下降模块(FGDM)的结构如下:**

1. 当图像退化过程A已知时,直接使用A计算梯度:

    $v_k = x_{k-1} - ρ_k A^T(Ax_{k-1} - y)$

这里ρ_k是第k阶段的可学习步长参数。

2. 当图像退化过程A未知时,采用数据驱动策略估计梯度:

    - 使用卷积块$F^k_A$、$F^k_{A^T}$估计$A$和$A^T$
    - 根据估计的$A$、$A^T$计算梯度:

    $v_k = x_{k-1} - ρ_k F^k_{A^T}(F^k_A(x_{k-1}) - y)$

3. FGDM的设计保持了可解释性,但不需要人为定义退化模型。

4. 通过学习来自数据的退化相关信息,实现了灵活的梯度估计。

5. 这种策略使得DGUNet可以处理复杂的真实退化情况,不需要人为设计精确的退化过程,增强了算法的适用性。

综上,FGDM是文章提出的创新之一,通过数据驱动的梯度预测,拓宽了网络的适用范围。

**论文中提出的信息融合的Proximal映射模块(IPMM)的结构如下:**

1. 使用通道注意力块(CAB)进行初步特征提取。

2. 使用了3个尺度的残差块(RB)提取多尺度特征,包括:

   - 编码器特征:$F^k_{enc} = {F^k_{enc⊛n}}$
   - 解码器特征:$F^k_{dec} = {F^k_{dec⊛n}}$

3. 使用最大池化下采样,双线性上采样实现尺度跳变。

4. 加入全局通道,直接传递低频信息。

5. 在每个尺度的编码器中,增加跨阶段特征融合模块(ISFF),进行空间自适应规范化。

6. ISFF模块可以传递前一阶段的编码器和解码器信息,增强当前特征表达。

7. 最终使用SAM模块提取清晰特征,为下一阶段提供输入。

8. IPMM表示为: 
   $x_k, F_k = prox_{θ^k}(v_k, F_{k-1})$

综上,IPMM采用hourglass设计获取多尺度特征,并在此基础上进行跨阶段的自适应信息融合,以弥补DUN的信息损失问题。

**论文中提出的跨阶段特征融合子模块(ISFF)的结构如下:**

1. 将前一阶段的编码器特征$F^{k-1}_{enc}$和解码器特征$F^{k-1}_{dec}$作为输入。

2. 对两者分别进行1x1卷积,得到两个新特征图。

3. 将两个特征图进行像素级的加法,得到融合特征$H_{k-1}$。

4. 利用$H_{k-1}$通过两个卷积层,分别学习出$α_k$和$β_k$,其中$α_k$和$β_k$的参数与空间位置(x,y)相关。

5. 对当前阶段的编码器中间特征图 $F^k_{enc}$, 进行如下变换:

   $F^k_{enc} = α_k \times F^k_{enc} + β_k$

6. 这里✖表示逐像素(元素)相乘,实现空间自适应规范化。

7. 如此,前一阶段的特征被注入到当前阶段,增强了网络的记忆能力和表达能力。

8. ISFF模块在网络的每个尺度上应用,以传递更丰富的特征。

整体来看,ISFF使用了自适应的跨阶段融合策略,使网络可以更充分地记忆和利用前期信息,弥补了DUN中特征损失的问题。

### 补充知识点

#### residual block

residual block(残差块)是残差网络(ResNet)中的基础构建模块,由Microsoft在2015年提出,是实现极深网络的关键。

residual block的结构如下:

输入x经过两个卷积层和ReLU激活函数,得到F(x)。
然后将F(x)与原输入x相加,得到残差块的输出:
y = F(x) + x

即将输入数据与卷积输出做shortcut相加。这种结构有以下优点:

1. 极大缓解了梯度消失问题,使得网络层数可以很深。

2. 引入了一条直通的信息流,有利于梯度反传。

3. 即使某层卷积模式出现问题,也可以通过shortcut传递信息,增强了网络的容错性。

在后续很多网络结构中,residual block已经成为标准的组件,用来构建非常深的模型。本文中也采用了residual block作为基础模块。

#### channel attention block

 通道注意力模块(Channel Attention Block)是一种常用的注意力机制,可以自适应地关注特征图在通道维度上的重要信息。

其结构通常如下:

- 输入特征图X首先进行全局池化,得到一个通道描述向量c
- 对c进行多层感知,得到权重向量w
- 权重w与特征X进行通道维度上的乘法,得到精简后的输出

也就是:

c = GAP(X) 
w = F(c)
Y = w * X

其中,F可以是多层全连接层,GAP表示全局平均池化。

这种结构可以学习每个通道的重要性,对重要通道赋予更高权重,不重要的通道权重更低。

从而达到自适应地强化有用特征,抑制无用特征的作用。是一种轻量有效的注意力机制,被广泛使用。

在本文中,作者在Proximal映射模块开始使用了CAB,对特征进行自适应提升。

#### bilinear upsampling

双线性插值上采样(Bilinear upsampling)是一种图像空间分辨率增强的方法,常用于深度网络中实现上采样。

其基本思想是:

1. 将图像放大到目标分辨率大小,插入新的像素点。

2. 对每个新增的像素点,根据其四邻域的已有像素值进行双线性插值,得到该像素的值。

具体来说,设要上采样的图像分辨率为H×W,目标分辨率为rH×rW,则对目标图像中的每个新的像素点(x,y):

1. 计算(x,y)对应在原图的坐标为(x', y'),一般x'=x/r, y'=y/r。

2. 根据(x', y')的四邻域的像素值{I(x', y'), I(x'+1, y'), I(x', y'+1), I(x'+1, y'+1)}进行双线性插值,求得I(x,y)。

3. 重复该过程,得到所有新增像素点的灰度,完成上采样。

这种上采样方式可以充分利用原图像信息,使得新增区域与原图像内容相关,所以结果更为自然。

在深度网络中,双线性上采样是一个简单有效的上采样操作,已被广泛使用。

#### supervised attention module

 Supervised Attention Module(SAM)是论文MPRNet中提出的一种注意力模块,可以用于提取目标域(如清晰图像)的相关特征。

其结构如下:

1. 输入特征图X先经过一个卷积层得到F。 

2. F分别经过1x1和3x3卷积,得到两个注意力特征A1和A3。

3. 对A1和A3通过softmax标准化,得到注意力权重W1和W3。

4. 利用W1和W3对F加权,得到两组注意力特征U1和U3。

5. U1和U3concat后接一个卷积层得到输出O。

6. O经过一个1x1卷积得到最终的attentive feature M。

其中,1x1卷积关注通道信息,3x3卷积关注位置信息。这样可以学习integrate不同感受野的注意力,进行有效的特征提取。

SAM模块提供了可学习性强的注意力机制,本文使用它来从特征中提取目标域信息,为网络提供反馈。

## 3.3 Loss Function Design

1. 采用了常用的L2损失函数来优化网络。

2. 给定受损图像y和ground-truth图像x。

3. 计算从每一阶段产生的输出图像x_k与x之间的L2距离。

4. 对所有K个阶段的Loss进行求和作为最终Loss。

5. 损失函数公式如下:

$L(Ω) = Σ_{k=1}^K ||x - ˆx_k||_2^2$

6. Ω表示网络所有可学习参数。

7. 通过最小化L,实现端到端的网络训练。

8. 这种简单的损失设计,可以有效地训练网络参数,同时也便于训练和复现。

这样的损失函数设计简洁明了,采用了L2重构误差作为优化目标,既考虑了不同阶段的输出,也方便了实际训练过程,可见作者对网络训练的经验与考虑。

# 4. Experiments

## 4.1 Training Details

使用Adam优化器,初始学习率2e-4
应用warming up strategy,逐步增大学习率
图像块尺寸:去雨/去模糊/去噪为256x256,压缩感知为32x32
批大小:去雨等为16,压缩感知为128
总迭代次数:去雨等为4x10^5次,压缩感知为200个Epoch
训练设备为2个Tesla V100 GPU
训练时间约为3天
使用PSNR和SSIM作为评价指标

## 4.2 Image Deraining Results

训练数据:11,200对,测试集:5个,共计4,828张图像
比较方法:DerainNet等8种
在所有测试集上取得显著提升,平均PSNR提高0.73dB
视觉上保留更好的纹理细节,有效去除各种程度的雨条

## 4.3 Image Deblurring Results

训练数据:2,103对图像
测试集:GoPro 1,111张,HIDE 2,025张
对比方法:DeblurGAN等12种
在两个测试集上均超过所有比较算法
生成的图像视觉效果更高,细节更丰富

## 4.4 Image Denoising Results

训练数据:SIDD 320对
测试集:SIDD和DND,共1,552张
对比方法:DANet等9种
在两个测试集上都取得新的state-of-the-art性能
可有效处理各种程度、类型的噪声

## 4.5 Compressive Sensing Results

训练数据:BSD400
测试集:Set11和BSD68
比较方法:opt-Net等7种
在不同下采样率上一致优于其他算法
重建的视觉效果更好,边缘清晰,纹理丰富

## 4.6 Ablation Study

1. 分析网络层数对性能的影响
   - 比较了9层、7层、5层和3层的模型效果
   - 结果显示:层数越多,性能越好
   - 验证了网络的级联设计对性能提升的有效性

2. 分析特征融合尺度数的影响
   - 测试了使用3尺度和2尺度的效果区别  
   - 结果显示:尺度数越多,效果越好
   - 说明多尺度特征融合的重要性

3. 拆解实验验证组件设计的有效性
   - 移除梯度预测模块,性能下降0.55dB
   - 移除空间注意力模块,性能下降0.14dB 
   - 移除跨阶段特征融合,性能下降1.97dB
   - 证明了这些模块的设计必要性

4. 实验都是在去雨任务的Rain100H数据集上进行

5. 采用PSNR指标评估模型性能

通过组件分解和超参数探究,充分验证了论文提出的模块设计、多尺度特征和级联结构对性能提升的有效性。

### 补充知识点

#### PSNR和SSIM

PSNR和SSIM是评价图像恢复质量常用的两种定量指标:

1. PSNR(Peak Signal-to-Noise Ratio)峰值信噪比,反映**恢复图像与原图的误差**。计算公式为:

$PSNR = 10 * log10(MAX^2 / MSE)$

其中,MAX是像素最大值,MSE为平均均方误差。**PSNR越高表示恢复图像越接近原图**。

2. SSIM(Structural Similarity Index)结构相似性,评价两**图像在结构/细节上的相似程度**。取值范围0-1,**越接近1表示两图结构越相似**。

计算SSIM时会在多个窗口内比较图像局部结构的相似性。

SSIM综合考虑了图像的亮度、对比度和结构信息。

综上,PSNR和SSIM从两方面反映恢复图像的质量。PSNR评价全局数值误差,SSIM评价结构/细节的相似性。两者结合可以更全面地评估算法的恢复效果。

#### CS ratios

在论文的压缩感知重建实验中提到的CS ratios表示不同的下采样率。

具体来说,CS ratio表示测量矩阵中保留了原始信号的百分比。一般用采样率s表示,定义为:

s = m / n

这里m是测量的维数,n是原始信号维数。

例如,当s=0.25时,表示随机保留了25%的原始采样,即压缩比为4。

论文中给出的CS ratios如下:

- 1%  (s=0.01)
- 4%  (s=0.04)  
- 10% (s=0.1)
- 25% (s=0.25)
- 50% (s=0.5)

即测试不同程度的下采样情况。

下采样率越低,重建难度越大。作者测试不同采样率可以全面验证方法的鲁棒性。

# 5. Conclusion and Discussion

1. 总结了文章的创新与贡献
   - 提出了可解释的深度广义展开网络DGUNet
   - 融入了灵活的梯度预测策略,可处理未知退化
   - 设计了跨层特征融合,降低了信息损失
   - 在多个图像恢复任务上获得了state-of-the-art的性能

2. 讨论了方法的优势
   - 保留了模型的可解释性
   - 可像端到端网络一样进行训练
   - 适用于复杂真实场景中图像的退化
   - 性能卓越且模型复杂度适中

3. 展望了未来的研究方向
   - 在MindSpore平台上支持DGUNet
   - 探索其他解释性网络结构
   - 加强对复杂退化过程的建模能力

4. 总结了文章的主要创新与贡献